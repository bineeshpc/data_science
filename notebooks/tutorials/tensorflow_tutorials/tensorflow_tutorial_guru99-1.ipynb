{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let 's define the X_1 and X_2 input nodes. When we create a node in Tensorflow, we have to choose what kind of node to create. The X1 and X2 nodes will be a placeholder node. The placeholder assigns a new value each time we make a calculation. We will create them as a TF dot placeholder node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = tf.placeholder(tf.float32, name=\"x_1\")\n",
    "x_2 = tf.placeholder(tf.float32, name=\"x_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply = tf.multiply(x_1, x_2, name=\"multiply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {\n",
    "    x_1: 5,\n",
    "    x_2: 2\n",
    "}\n",
    "\n",
    "with tf.Session() as session:\n",
    "    result = session.run(multiply, feed_dict=feed_dict)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5. 20. 60.]\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {\n",
    "    x_1: [1, 2, 3],\n",
    "    x_2: [5, 10, 20]\n",
    "}\n",
    "\n",
    "with tf.Session() as session:\n",
    "    result = session.run(multiply, feed_dict=feed_dict)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1189361 , 0.29490829],\n",
       "       [0.58307463, 0.24014216],\n",
       "       [0.28303032, 0.10422136]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input = np.random.sample((3, 2))\n",
    "x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'X:0' shape=(3, 2) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[3, 2], name='X')\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf.data.Dataset API supports writing descriptive and efficient input pipelines. Dataset usage follows a common pattern:\n",
    "\n",
    "Create a source dataset from your input data.\n",
    "Apply dataset transformations to preprocess the data.\n",
    "Iterate over the dataset and process the elements.\n",
    "Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory.\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/data/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\M1057101\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "\n",
    "iterator = dataset.make_initializable_iterator() \n",
    "get_next = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1189361 0.2949083]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # feed the placeholder with data\n",
    "    sess.run(iterator.initializer, feed_dict={ x: x_input }) \n",
    "    print(sess.run(get_next)) # output [ 0.52374458  0.71968478]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1189361 0.2949083]\n",
      "[0.5830746  0.24014217]\n",
      "[0.2830303  0.10422137]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # feed the placeholder with data\n",
    "    sess.run(iterator.initializer, feed_dict={ x: x_input })\n",
    "    while True:\n",
    "        try:\n",
    "            res = sess.run(get_next)\n",
    "            print(res)\n",
    "        except:          \n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
