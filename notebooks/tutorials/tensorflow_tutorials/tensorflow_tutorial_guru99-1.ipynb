{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let 's define the X_1 and X_2 input nodes. When we create a node in Tensorflow, we have to choose what kind of node to create. The X1 and X2 nodes will be a placeholder node. The placeholder assigns a new value each time we make a calculation. We will create them as a TF dot placeholder node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = tf.placeholder(tf.float32, name=\"x_1\")\n",
    "x_2 = tf.placeholder(tf.float32, name=\"x_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply = tf.multiply(x_1, x_2, name=\"multiply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {\n",
    "    x_1: 5,\n",
    "    x_2: 2\n",
    "}\n",
    "\n",
    "with tf.Session() as session:\n",
    "    result = session.run(multiply, feed_dict=feed_dict)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5. 20. 60.]\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {\n",
    "    x_1: [1, 2, 3],\n",
    "    x_2: [5, 10, 20]\n",
    "}\n",
    "\n",
    "with tf.Session() as session:\n",
    "    result = session.run(multiply, feed_dict=feed_dict)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32586168, 0.55436094],\n",
       "       [0.89554821, 0.92957463],\n",
       "       [0.60478755, 0.14531606]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input = np.random.sample((3, 2))\n",
    "x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'X_8:0' shape=(3, 2) dtype=float32>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[3, 2], name='X')\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf.data.Dataset API supports writing descriptive and efficient input pipelines. Dataset usage follows a common pattern:\n",
    "\n",
    "Create a source dataset from your input data.\n",
    "Apply dataset transformations to preprocess the data.\n",
    "Iterate over the dataset and process the elements.\n",
    "Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory.\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/data/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "\n",
    "iterator = dataset.make_initializable_iterator() \n",
    "get_next = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32586166 0.5543609 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # feed the placeholder with data\n",
    "    sess.run(iterator.initializer, feed_dict={ x: x_input }) \n",
    "    print(sess.run(get_next)) # output [ 0.52374458  0.71968478]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32586166 0.5543609 ]\n",
      "[0.8955482 0.9295746]\n",
      "[0.6047875  0.14531606]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # feed the placeholder with data\n",
    "    sess.run(iterator.initializer, feed_dict={ x: x_input })\n",
    "    while True:\n",
    "        try:\n",
    "            res = sess.run(get_next)\n",
    "            print(res)\n",
    "        except:          \n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
